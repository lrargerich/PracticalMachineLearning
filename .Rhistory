for (i in 1:10000) {
r<-mean(rexp(40,lambda))
g=c(g,r)
}
gd<-as.data.frame(g)
mean(g)
1/lambda
1/lambda
sd(g)
mean(g) * (1/lambda) / sqrt(40)
mean(rexp(40,lambda)) * (1/lambda) / sqrt(40)
mean(rexp(40,lambda)) * (1/lambda) / sqrt(39)
mean(rexp(40,lambda)) / sqrt(40)
1/lambda / sqrt(40) # theoretical sd of simulation
ggplot(gd,aes(x=g)) + geom_histogram(aes(y=..density..),binwidth=.5,colour="black",fill="white") +
geom_density(alpha=.2,fill="#FF6666") +
geom_vline(aes(xintercept=mean(g, na.rm=T)),   # Ignore NA values for mean
color="red", linetype="dashed", size=1) +
scale_x_continuous(breaks=seq(0,60,5)) +
stat_function(colour="green",geom="line", fun=dnorm, arg=list(mean=1/0.2, sd=0.79))
dataset(ToothGrowth)
data(ToothGrowth)
str(ToothGrowth)
t<-data(ToothGrowth)
t<-as.data.frame(data(ToothGrowth))
str(ToothGrowth)
ToothGrowth$dose<-as.factor(ToothGrowth$dose)
str(ToothGrowth)
qplot(ToothGrowth$supp,ToothGrowth$dose,size=len)
qplot(ToothGrowth$supp,ToothGrowth$dose,size=ToothGrowth$len)
qplot(jitter(ToothGrowth$supp),jitter(ToothGrowth$dose),size=ToothGrowth$len)
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose),size=ToothGrowth$len)
)
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose)),
size=ToothGrowth$len)
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose)),
size=ToothGrowth$len,color="blue")
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose)),
size=ToothGrowth$len)
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose)),
size=ToothGrowth$len,ylab="dose")
qplot(jitter(as.numeric(ToothGrowth$supp)),jitter(as.numeric(ToothGrowth$dose)),
size=ToothGrowth$len,ylab="dose",xlab="supp")
?ToothGrowth
str(ToothGrowth)
summary(ToothGrowth)
ToothGrowth[dose==0.5,]
ToothGrowth[ToothGrowth$dose==0.5,]
ToothGrowth[ToothGrowth$dose==0.5,1]
group1<-ToothGrowth[ToothGrowth$dose==0.5,1]
group2<-ToothGrowth[ToothGrowth$dose==2,1]
t.test(group1,group2,paired=FALSE)
group1<-ToothGrowth[ToothGrowth$supp=="VC"]
group1<-ToothGrowth[ToothGrowth$supp=='VC']
group1<-ToothGrowth[ToothGrowth$supp==2]
group2<-ToothGrowth[ToothGrowth$supp==1]
group1
ToothGrowth$supp==1
ToothGrowth$supp=="VC"
group1<-ToothGrowth[ToothGrowth$supp=="VC",1]
group2<-ToothGrowth[ToothGrowth$supp=="OCJ",1]
str(ToothGrowth)
group2<-ToothGrowth[ToothGrowth$supp=="OJ",1]
t.test(group1,group2,paired=FALSE)
setwd("E:/JH/PracticalMachineLearning")
train<-read.csv("pml-training.csv",strings.as.factors=FALSE)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
View(train)
str(train)
str(test)
View(test)
train$classe
colnames(train)
setfiff(colnames(train),colnames(test))
setdiff(colnames(train),colnames(test))
setdiff(colnames(test),colnames(train))
train$X<-NULL
train$user_name<-NULL
train$raw_timestamp_part1<-NULL
train$raw_timestamp_part2<-NULL
train$cvtd_timestamp<-NULL
train$new_window<-NULL
train$raw_timestamp_part_1<-NULL
train$raw_timestamp_part_2<-NULL
str(train)
train$num_window<-NULL
train$X<-NULL;test$X<-NULL
train$user_name<-NULL;test$user_name<-NULL
train$raw_timestamp_part_1<-NULL;test$raw_timestamp_part_1<-NULL
train$cvtd_timestamp<-NULL;test$cvtd_timestamp<-NULL
train$raw_timestamp_part_2<-NULL;test$raw_timestamp_part_2<-NULL
train$new_window<-NULL;test$new_window<-NULL
train$num_window<-NULL;test$num_window<-NULL
train <- train[,colSums(is.na(train))<nrow(train)]
library(caret)
asNumeric <- function(x) as.numeric(as.character(as.numeric(x)))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
train<-factorsNumeric(train)
test<-factorsNumeric(test)
str(train)
train <- train[,colSums(is.na(train))<nrow(train)]
?preProcess
train2<-preProcess(train,method="knnImpute")
otrain2<-preProcess(train,method="knnImpute")
train2<-predict(otrain2,train)
install.packages("RANN")
library(RANN)
train2<-predict(otrain2,train)
otrain2<-preProcess(train,method="medianImpute")
train2<-predict(otrain2,train)
str(train2)
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train2<-predict(obj,train)
View(train2)
objpca<-prePRocess(train2,method="pca",thresh=0.9)
objpca<-preProcess(train2,method="pca",thresh=0.9)
objpca$numComp
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train<-predict(obj,train)
test<-predict(obj,test)
train$classe<-NULL
test$problem_id<-NULL
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train$X<-NULL;test$X<-NULL
train$user_name<-NULL;test$user_name<-NULL
train$raw_timestamp_part_1<-NULL;test$raw_timestamp_part_1<-NULL
train$raw_timestamp_part_2<-NULL;test$raw_timestamp_part_2<-NULL
train$cvtd_timestamp<-NULL;test$cvtd_timestamp<-NULL
train$new_window<-NULL;test$new_window<-NULL
train$num_window<-NULL;test$num_window<-NULL
asNumeric <- function(x) as.numeric(as.character(as.numeric(x)))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
train<-factorsNumeric(train)
test<-factorsNumeric(test)
problem_id<-test$problem_id
classe<-train$classe
train$classe<-NULL
test$problem_id<-NULL
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train<-predict(obj,train)
test<-predict(obj,test)
objpca<-preProcess(train,method="pca",thresh=0.9)
train<-predict(objpca,train)
test<-predict(objpca,test)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train$X<-NULL;test$X<-NULL
train$user_name<-NULL;test$user_name<-NULL
train$raw_timestamp_part_1<-NULL;test$raw_timestamp_part_1<-NULL
train$raw_timestamp_part_2<-NULL;test$raw_timestamp_part_2<-NULL
train$cvtd_timestamp<-NULL;test$cvtd_timestamp<-NULL
train$new_window<-NULL;test$new_window<-NULL
train$num_window<-NULL;test$num_window<-NULL
problem_id<-test$problem_id
classe<-as.factor(train$classe)
asNumeric <- function(x) as.numeric(as.character(as.numeric(x)))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
train<-factorsNumeric(train)
test<-factorsNumeric(test)
train$classe<-NULL
test$problem_id<-NULL
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train<-predict(obj,train)
test<-predict(obj,test)
objpca<-preProcess(train,method="pca",thresh=0.9)
train<-predict(objpca,train)
test<-predict(objpca,test)
intTr<-createDataPartition(y=train$label,p=0.7,list=FALSE)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train$X<-NULL;test$X<-NULL
train$user_name<-NULL;test$user_name<-NULL
train$raw_timestamp_part_1<-NULL;test$raw_timestamp_part_1<-NULL
train$raw_timestamp_part_2<-NULL;test$raw_timestamp_part_2<-NULL
train$cvtd_timestamp<-NULL;test$cvtd_timestamp<-NULL
train$new_window<-NULL;test$new_window<-NULL
train$num_window<-NULL;test$num_window<-NULL
id<-as.data.frame(test$problem_id)
names(id)<-"problem)id"
labels<-as.data.frame(as.factor(train$classe))
names(labels)<-"label"
asNumeric <- function(x) as.numeric(as.character(as.numeric(x)))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
train<-factorsNumeric(train)
test<-factorsNumeric(test)
train$classe<-NULL
test$problem_id<-NULL
# Input missing values, center, scale and dimensionality reduction
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train<-predict(obj,train)
test<-predict(obj,test)
objpca<-preProcess(train,method="pca",thresh=0.9)
train<-predict(objpca,train)
test<-predict(objpca,test)
train<-cbind(classe,train)
intTr<-createDataPartition(y=train$label,p=0.7,list=FALSE)
View(train)
train<-read.csv("pml-training.csv")
test<-read.csv("pml-testing.csv")
train$classe
summary(train$classe)
train$X<-NULL;test$X<-NULL
train$user_name<-NULL;test$user_name<-NULL
train$raw_timestamp_part_1<-NULL;test$raw_timestamp_part_1<-NULL
train$raw_timestamp_part_2<-NULL;test$raw_timestamp_part_2<-NULL
train$new_window<-NULL;test$new_window<-NULL
train$cvtd_timestamp<-NULL;test$cvtd_timestamp<-NULL
train$num_window<-NULL;test$num_window<-NULL
id<-as.data.frame(test$problem_id)
names(id)<-"problem)id"
labels<-as.data.frame(as.factor(train$classe))
id
labels
summary(labels)
names(labels)<-"label"
summary(labels)
train<-factorsNumeric(train)
test<-factorsNumeric(test)
train$classe<-NULL
test$problem_id<-NULL
# Input missing values, center, scale and dimensionality reduction
obj<-preProcess(train,method=c("medianImpute","center","scale"))
train<-predict(obj,train)
test<-predict(obj,test)
objpca<-preProcess(train,method="pca",thresh=0.9)
train<-predict(objpca,train)
test<-predict(objpca,test)
# add the label again
train<-cbind(labels,train)
intTr<-createDataPartition(y=train$label,p=0.7,list=FALSE)
t1<-train[intTr,]
t2<-train[-intTr,]
rm(intTr)
train_predictions<-as.data.frame(t2$label)
View(train_predictions)
names(train_predictions)<-"label"
test_predictions<-as.data.frame(id)
names(test_predictions)<-"id"
source('E:/JH/PracticalMachineLearning/modeling.R')
source('E:/JH/PracticalMachineLearning/modeling.R')
source('E:/JH/PracticalMachineLearning/modeling.R')
t1_predictions<-as.data.frame(t1$label)
t2_predictions<-as.data.frame(t2$label)
names(t1_predictions)<-"label"
names(t2_predictions)<-"label"
test_predictions<-as.data.frame(id)
names(test_predictions)<-"id"
max_acc<-0
best_method="none"
accdf<-data.frame(method="",accuracy=0)
accdf<-accdf[-1]
for (method in c("gbm","rf","svmRadial","C5.0","RRF")) {
print (paste("Running:",method))
# Fit training
fit<-train(as.factor(t1$label)~.,method=method,data=t1)
# Save Model
save(fit,file=paste("model_",method,".model",sep=""))
# Make predictions
pred_t1<-predict(fit,t1)
pred_t2<-predict(fit,t2[,-1])
pred_test<-predict(fit,test)
# Compute Accuracy
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
accdf<-rbind(accdf,c(method,acc))
write.csv(accdf,"accuracy.csv",row.names=FALSE)
if (acc>max_acc) {
max_acc <- acc
best_method <- method
}
# Aggregate
pred_t1<-as.data.frame(pred_t1)
pred_t2<-as.data.frame(pred_t2)
pred_test<-as.data.frame(pred_test)
names(pred_t1)<-method
names(pred_t2)<-method
names(pred_test)<-method
t1_predictions<-cbind(t1_predictions,pred_t1)
t2_predictions<-cbind(t2_predictions,pred_t2)
test_predictions<-cbind(test_predictions,pred_test)
# Save Aggregate
method="gbm"
)
method="gbm"
accdf<-accdf[-1]
method="gbm"
print (paste("Running:",method))
# Fit training
fit<-train(as.factor(t1$label)~.,method=method,data=t1)
# Save Model
save(fit,file=paste("model_",method,".model",sep=""))
# Make predictions
pred_t1<-predict(fit,t1)
pred_t2<-predict(fit,t2[,-1])
pred_test<-predict(fit,test)
# Compute Accuracy
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
accdf<-rbind(accdf,c(method,acc))
write.csv(accdf,"accuracy.csv",row.names=FALSE)
if (acc>max_acc) {
max_acc <- acc
best_method <- method
}
# Aggregate
pred_t1<-as.data.frame(pred_t1)
pred_t2<-as.data.frame(pred_t2)
pred_test<-as.data.frame(pred_test)
names(pred_t1)<-method
names(pred_t2)<-method
names(pred_test)<-method
t1_predictions<-cbind(t1_predictions,pred_t1)
t2_predictions<-cbind(t2_predictions,pred_t2)
test_predictions<-cbind(test_predictions,pred_test)
View(accdf)
# Save Aggregate
write.csv(t1_predictions,"t1_predictions.csv",row.names=FALSE)
write.csv(t2_predictions,"t2_predictions.csv",row.names=FALSE)
# NOW create prediction for test set
result <- pred_test
### IMPORTANT TO CHANGE THIS
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
names(result)<-method
write.csv(submit, file = paste("submit_",method,".csv",sep=""), row.names = FALSE)
}
for (method in c("rf","svmRadial","C5.0","RRF")) {
print (paste("Running:",method))
# Fit training
fit<-train(as.factor(t1$label)~.,method=method,data=t1)
# Save Model
save(fit,file=paste("model_",method,".model",sep=""))
# Make predictions
pred_t1<-predict(fit,t1)
pred_t2<-predict(fit,t2[,-1])
pred_test<-predict(fit,test)
# Compute Accuracy
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
accdf<-rbind(accdf,c(method,acc))
write.csv(accdf,"accuracy.csv",row.names=FALSE)
if (acc>max_acc) {
max_acc <- acc
best_method <- method
}
# Aggregate
pred_t1<-as.data.frame(pred_t1)
pred_t2<-as.data.frame(pred_t2)
pred_test<-as.data.frame(pred_test)
names(pred_t1)<-method
names(pred_t2)<-method
names(pred_test)<-method
t1_predictions<-cbind(t1_predictions,pred_t1)
t2_predictions<-cbind(t2_predictions,pred_t2)
test_predictions<-cbind(test_predictions,pred_test)
# Save Aggregate
write.csv(t1_predictions,"t1_predictions.csv",row.names=FALSE)
write.csv(t2_predictions,"t2_predictions.csv",row.names=FALSE)
# NOW create prediction for test set
result <- pred_test
### IMPORTANT TO CHANGE THIS
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
names(result)<-method
write.csv(submit, file = paste("submit_",method,".csv",sep=""), row.names = FALSE)
}
acc<- sum((pred == t2$label))/length(t2$label)
acc<- sum((pred_t2 == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
accdf<-rbind(accdf,c(method,acc))
View(accdf)
method
acc
accdf<-rbind(accdf,as.data.frame(c(method,acc)))
accdf<-rbind(accdf,c(method,acc))
View(accdf)
accdf<-rbind(accdf,data.frame(method = method,accuracy = acc))
View(accdf)
names(accdf)<-"method","accuracy"
names(accdf)<-c("method","accuracy")
accdf<-rbind(accdf,data.frame(method = method,accuracy = acc))
View(accdf)
accdf$method = rbind(accdf$method,method)
accdf$method = rbind(accdf$method,toString(method))
accdf1<-data.frame(method=method,accuracy=acc)
View(accdf1)
View(accdf)
accdf = rbind(accdf,accdf1)
View(accdf)
accdf1<-data.frame(method=method,accuracy=toString(acc))
accdf = rbind(accdf,accdf1)
View(accdf)
write.csv(accdf,"accuracy.csv",row.names=FALSE)
if (acc>max_acc) {
max_acc <- acc
best_method <- method
}
# Aggregate
pred_t1<-as.data.frame(pred_t1)
pred_t2<-as.data.frame(pred_t2)
pred_test<-as.data.frame(pred_test)
names(pred_t1)<-method
names(pred_t2)<-method
names(pred_test)<-method
t1_predictions<-cbind(t1_predictions,pred_t1)
t2_predictions<-cbind(t2_predictions,pred_t2)
test_predictions<-cbind(test_predictions,pred_test)
View(test_predictions)
View(`t1_predictions`)
t1_predictions
str(t1_predictions)
str(t1$label)
summary(t1$label)
summary(t1_predictions$label)
summary(t1_predictions$rf)
summary(t1_predictions$gbm)
# Save Aggregate
write.csv(t1_predictions,"t1_predictions.csv",row.names=FALSE)
write.csv(t2_predictions,"t2_predictions.csv",row.names=FALSE)
# NOW create prediction for test set
result <- pred_test
### IMPORTANT TO CHANGE THIS
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
names(result)<-method
write.csv(submit, file = paste("submit_",method,".csv",sep=""), row.names = FALSE)
}
for (method in c("svmRadial","C5.0","RRF","nnet")) {
print (paste("Running:",method))
# Fit training
fit<-train(as.factor(t1$label)~.,method=method,data=t1)
# Save Model
save(fit,file=paste("model_",method,".model",sep=""))
# Make predictions
pred_t1<-predict(fit,t1)
pred_t2<-predict(fit,t2[,-1])
pred_test<-predict(fit,test)
# Compute Accuracy
acc<- sum((pred_t2 == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
accdf1<-data.frame(method=method,accuracy=toString(acc))
accdf = rbind(accdf,accdf1)
write.csv(accdf,"accuracy.csv",row.names=FALSE)
if (acc>max_acc) {
max_acc <- acc
best_method <- method
}
# Aggregate
pred_t1<-as.data.frame(pred_t1)
pred_t2<-as.data.frame(pred_t2)
pred_test<-as.data.frame(pred_test)
names(pred_t1)<-method
names(pred_t2)<-method
names(pred_test)<-method
t1_predictions<-cbind(t1_predictions,pred_t1)
t2_predictions<-cbind(t2_predictions,pred_t2)
test_predictions<-cbind(test_predictions,pred_test)
# Save Aggregate
write.csv(t1_predictions,"t1_predictions.csv",row.names=FALSE)
write.csv(t2_predictions,"t2_predictions.csv",row.names=FALSE)
# NOW create prediction for test set
result <- pred_test
### IMPORTANT TO CHANGE THIS
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
names(result)<-method
write.csv(submit, file = paste("submit_",method,".csv",sep=""), row.names = FALSE)
}
library(randomForest)
tuneRF(x=t1[,-1],y=as.factor(t1$label), improve=0.002, trace=TRUE)
clf <- randomForest(t1[,-1], as.factor(t1$label), ntree=500, mtry=4, importance=TRUE)
clf
pred<-predict(clf,t2[,-1])
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
result<-predict(clf,test)
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
write.csv(submit, file = paste("submit.csv",sep=""), row.names = FALSE)
t1[,-1]
head(t1[,-1])
fit<-train(as.factor(t1$label)~.,method="gbm",data=t1)
fit<-train(as.factor(t1$label)~.,method="nnet",data=t1)
fit
pred<-predict(fit,t2[,-1])
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
fit<-train(as.factor(t1$label)~.,method="gbm",data=t1)
fit
pred<-predict(fit,t2[,-1])
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
result<-predict(fit,test)
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
write.csv(submit, file = paste("submit_gbm.csv",sep=""), row.names = FALSE)
fit<-train(as.factor(t1$label)~.,method="RRF",data=t1)
fit<-train(as.factor(t1$label)~.,method="svmRadial",data=t1)
fit
pred<-predict(fit,t2[,-1])
acc<- sum((pred == t2$label))/length(t2$label)
print (paste("Accuracy for ",method,":",acc))
result<-predict(fit,test)
submit <- data.frame(problem_id = id, classe = result)
result<-as.data.frame(result)
write.csv(submit, file = paste("submit_svm.csv",sep=""), row.names = FALSE)
